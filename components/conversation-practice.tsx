"use client"

import { useState, useRef, useEffect, useMemo, useCallback } from "react"
import { motion, AnimatePresence } from "framer-motion"
import { Button } from "@/components/ui/button"
import { Input } from "@/components/ui/input"
import { Card, CardContent } from "@/components/ui/card"
import { Volume2, Languages, Eye, Bookmark, Mic, X, ArrowUp, Settings, Lightbulb, Loader2 } from "lucide-react"
import { useLearningContext } from "@/contexts/LearningContext"
import { apiClient } from "@/lib/api"
import { SuccessPopup } from "@/components/success-popup"
import { useVad } from "@/hooks/use-vad"

interface ConversationPracticeProps {
  scenario: any
  onBack: () => void
  initialMessage?: {
    text: string
    translation: string
  }
}

interface Message {
  id: string
  role: "user" | "assistant"
  text: string
  translation?: string
  translateEn?: string
  isWaiting?: boolean
  isCurrentlyRecording?: boolean
  isCancelled?: boolean
  isFeedback?: boolean
}

export function ConversationPractice({ scenario, onBack, initialMessage }: ConversationPracticeProps) {
  const {
    currentTaskIndex,
    currentTask,
    progress,
    isListening,
    isAgentSpeaking,
    sessionId,
    attempts,
    setListening,
    setAgentSpeaking,
    markCurrentTaskSuccess,
    gotoNextTask,
    incrementAttempts,
    saveProgress,
    latchTaskSuccesses,
  } = useLearningContext()

  const [showHintTranslation, setShowHintTranslation] = useState(false)
  const [showAssistantTranslation, setShowAssistantTranslation] = useState(false)
  const [showHint, setShowHint] = useState(false)
  const [isSaved, setIsSaved] = useState(false)
  const [isRecording, setIsRecording] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [recordingDuration, setRecordingDuration] = useState(0)
  const [feedback, setFeedback] = useState<string | null>(null)
  // score removed per new design (metadata split)
  const [currentlyRecordingMessageId, setCurrentlyRecordingMessageId] = useState<string | null>(null)
  const [hint, setHint] = useState<string | null>(null)
  const [hintTranslateEn, setHintTranslateEn] = useState<string | null>(null)
  const [isHintPlaying, setIsHintPlaying] = useState(false)
  const [isHintLoading, setIsHintLoading] = useState(false)
  const [isHintTranslating, setIsHintTranslating] = useState(false)
  const [hintTaskIndex, setHintTaskIndex] = useState<number | null>(null)
  const [isCancelled, setIsCancelled] = useState(false)
  const [cancelledMessageId, setCancelledMessageId] = useState<string | null>(null)
  const [showSuccessPopup, setShowSuccessPopup] = useState(false)
  const [textOnlyMode, setTextOnlyMode] = useState<boolean>(
    () => (typeof process !== "undefined" && process.env.NEXT_PUBLIC_TEXT_ONLY_CHAT === "true") || false
  )
  const [typedMessage, setTypedMessage] = useState<string>("")
  const [translatingMessageId, setTranslatingMessageId] = useState<string | null>(null)
  
  // Show success popup only when all tasks are completed (by success)
  useEffect(() => {
    if (progress.total > 0 && progress.completed === progress.total) {
      setShowSuccessPopup(true)
    }
  }, [progress.completed, progress.total])
  
  // VAD ê´€ë ¨ ìƒíƒœ (UIì—ì„œ ì œê±°, ë‚´ë¶€ ì²˜ë¦¬ë§Œ ìœ ì§€)
  const [vadErrorMessage, setVadErrorMessage] = useState<string | null>(null)
  const [messages, setMessages] = useState<Message[]>(() => {
    const defaultInitialMessage = {
      text: "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë¡œë¹ˆì´ì—ìš”. ì—ì´ë¯¸ ì¹œêµ¬ë§ìœ¼ì„¸ìš”?",
      translation: "Hi, I'm Robin! Are you Amy's friend?",
    }
    
    const initialMsg = initialMessage || scenario.initialMessage || defaultInitialMessage
    
    return [
      {
        id: "initial",
        role: "assistant",
        text: initialMsg.text,
        translation: initialMsg.translation,
      },
      {
        id: "user-waiting",
        role: "user",
        text: "",
        isWaiting: true,
      },
    ]
  })


  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])
  const recordingTimerRef = useRef<NodeJS.Timeout | null>(null)
  const audioRef = useRef<HTMLAudioElement | null>(null)
  const hintAudioRef = useRef<HTMLAudioElement | null>(null)
  const isCancelledRef = useRef<boolean>(false)
  const hasPlayedInitialTtsRef = useRef<boolean>(false)
  const vadUtterancesRef = useRef<Array<{ url: string; durationMs: number; timestamp: number }>>([])
  const recordingStartTimeRef = useRef<number>(0)
  
  // VAD í›… ì´ˆê¸°í™” (UI ìƒíƒœ ì œê±°)
  const {
    lastUtterance: vadLastUtterance,
    error: vadError,
    start: vadStart,
    stop: vadStop,
  } = useVad()

  // TEMP: disable initial TTS autoplay
  const ENABLE_INITIAL_TTS = false

  // VAD ë°œí™” êµ¬ê°„ ì²˜ë¦¬ - UI ìƒíƒœ ì œê±°ë¡œ ë¦¬ë Œë”ë§ ì™„ì „ ì œê±°
  useEffect(() => {
    if (vadLastUtterance) {
      const utterance = {
        url: vadLastUtterance.url,
        durationMs: vadLastUtterance.durationMs,
        timestamp: Date.now()
      }
      
      // refì—ë§Œ ì €ì¥ (UI ìƒíƒœ ì—…ë°ì´íŠ¸ ì—†ìŒ)
      vadUtterancesRef.current = [...vadUtterancesRef.current, utterance]
    }
  }, [vadLastUtterance])

  // VAD ì—ëŸ¬ ì²˜ë¦¬ - ë¦¬ë Œë”ë§ ìµœì†Œí™”
  useEffect(() => {
    if (vadError) {
      // ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì²˜ë¦¬í•˜ë˜, ìƒíƒœ ì—…ë°ì´íŠ¸ëŠ” ìµœì†Œí™”
      console.error("âŒ VAD Error:", vadError)
      setVadErrorMessage(vadError)
    }
  }, [vadError])

  // VAD ìƒíƒœ ë³€í™” ë¡œê¹… (ì œê±° - ì „ì†¡ ì‹œì ì—ë§Œ ìš”ì•½ ì¶œë ¥)

  // Removed initialHint support: hints are fetched on demand

  // Play initial assistant message TTS on mount / when initial message changes
  useEffect(() => {
    if (!ENABLE_INITIAL_TTS) return
    if (hasPlayedInitialTtsRef.current) return

    // Determine initial message text following the same precedence as initial state
    const defaultInitialMessage = {
      text: "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë¡œë¹ˆì´ì—ìš”. ì—ì´ë¯¸ ì¹œêµ¬ë§ìœ¼ì„¸ìš”?",
      translation: "Hi, I'm Robin! Are you Amy's friend?",
    }
    const initialMsg = initialMessage || (scenario as any).initialMessage || defaultInitialMessage
    const text = initialMsg?.text
    if (!text) return

    let isActive = true
    ;(async () => {
      try {
        setAgentSpeaking(true)
        const audioUrl = await apiClient.getOrCreateTtsObjectUrl(text, {
          sessionId,
          voice: scenario.ttsVoice || "nova",
          format: "mp3",
          instructions: scenario.ttsInstructions,
        })

        if (!isActive) return

        // Stop any existing audio
        if (audioRef.current) {
          try { audioRef.current.pause() } catch {}
        }

        const audio = new Audio(audioUrl)
        audioRef.current = audio
        hasPlayedInitialTtsRef.current = true

        await new Promise<void>((resolve) => {
          audio.onended = () => resolve()
          audio.onerror = () => resolve()
          audio.play().catch(() => resolve())
        })
      } catch {
        // noop â€“ failures should not block interaction
      } finally {
        if (isActive) setAgentSpeaking(false)
      }
    })()

    return () => {
      isActive = false
    }
  }, [initialMessage?.text, sessionId, setAgentSpeaking, apiClient, scenario])

  // Recording functionality
  useEffect(() => {
    return () => {
      // Cleanup on unmount
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current)
      }
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
        mediaRecorderRef.current.stop()
      }
      if (audioRef.current) {
        audioRef.current.pause()
        audioRef.current = null
      }
      if (hintAudioRef.current) {
        hintAudioRef.current.pause()
        hintAudioRef.current = null
      }
      // Clear audio cache on unmount
      apiClient.clearAudioCache()
    }
  }, [])

  const startRecording = async () => {
    if (textOnlyMode) return
    try {
      // ì·¨ì†Œ ìƒíƒœ ì´ˆê¸°í™”
      setIsCancelled(false)
      setCancelledMessageId(null)
      isCancelledRef.current = false
      
      // VAD ë°œí™” êµ¬ê°„ ì´ˆê¸°í™” (UI ìƒíƒœ ì œê±°)
      vadUtterancesRef.current = [] // refë§Œ ì´ˆê¸°í™”
      
      // ë°œí™” ì‹œì‘ ì‹œ íŒíŠ¸ ìë™ ìˆ¨ê¹€
      if (showHint) {
        setShowHint(false)
      }

      // í˜„ì¬ ëŒ€ê¸° ì¤‘ì¸ ë©”ì‹œì§€ ID ì°¾ê¸°
      const waitingMessage = messages.find(msg => msg.role === "user" && msg.isWaiting)
      console.log('Found waiting message:', waitingMessage)
      if (waitingMessage) {
        setCurrentlyRecordingMessageId(waitingMessage.id)
        console.log('Set currentlyRecordingMessageId to:', waitingMessage.id)
      }

      // VAD ì‹œì‘
      try {
        await vadStart()
        setVadErrorMessage(null) // ì—ëŸ¬ ë©”ì‹œì§€ ì´ˆê¸°í™”
      } catch (vadError) {
        setVadErrorMessage(vadError instanceof Error ? vadError.message : String(vadError))
      }

      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: "audio/webm;codecs=opus",
      })

      mediaRecorderRef.current = mediaRecorder
      audioChunksRef.current = []

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
        }
      }

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: "audio/webm" })
        stream.getTracks().forEach(track => track.stop())
        
        // VAD ì¤‘ì§€
        vadStop()
        
        // ì·¨ì†Œ ìƒíƒœ í™•ì¸í•˜ì—¬ ë¶„ê¸° ì²˜ë¦¬ (ref ì‚¬ìš©ìœ¼ë¡œ ìµœì‹  ìƒíƒœ ì°¸ì¡°)
        console.log('onstop event - isCancelledRef.current:', isCancelledRef.current)
        if (isCancelledRef.current) {
          // ì·¨ì†Œëœ ê²½ìš°: processAudio í˜¸ì¶œí•˜ì§€ ì•ŠìŒ
          console.log('Recording was cancelled, skipping processAudio')
          handleCancelledRecording()
        } else {
          // ì •ìƒ ì¤‘ë‹¨ëœ ê²½ìš°: VAD ë°œí™” êµ¬ê°„ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì „ì²´ ì˜¤ë””ì˜¤ ì‚¬ìš©
          console.log('ğŸ™ï¸ ë…¹ìŒ ì™„ë£Œ - ì˜¤ë””ì˜¤ ë¶„ì„ ì‹œì‘')
          
          // VAD ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥ (UI ìƒíƒœ ì œê±°ë¡œ ë‹¨ìˆœí™”)
          const currentUtterances = vadUtterancesRef.current
          
          console.log('ğŸ“Š === VAD ë¶„ì„ ê²°ê³¼ ìš”ì•½ ===')
          console.log(`ğŸ¯ ì²˜ë¦¬ ë°©ì‹: ${currentUtterances.length > 0 ? 'VAD ë°œí™” êµ¬ê°„ ì‚¬ìš©' : 'ì „ì²´ ì˜¤ë””ì˜¤ ì‚¬ìš©'}`)
          console.log(`ğŸ¤ ê°ì§€ëœ ë°œí™” êµ¬ê°„: ${currentUtterances.length}ê°œ`)
          if (vadErrorMessage) {
            console.log(`âš ï¸ VAD ì—ëŸ¬: ${vadErrorMessage}`)
          }
          console.log('===============================')
          
          if (currentUtterances.length > 0) {
            await processVadUtterances()
          } else {
            await processAudio(audioBlob)
          }
        }
      }

      mediaRecorder.start()
      setIsRecording(true)
      setListening(true)
      setRecordingDuration(0)
      
      // ì •í™•í•œ ë…¹ìŒ ì‹œì‘ ì‹œê°„ ê¸°ë¡
      recordingStartTimeRef.current = Date.now()

      // Start timer
      recordingTimerRef.current = setInterval(() => {
        setRecordingDuration(prev => prev + 1)
      }, 1000)
    } catch (error) {
      console.error("Error starting recording:", error)
      alert("ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
    }
  }

  const stopRecording = () => {
    if (textOnlyMode) return
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
      mediaRecorderRef.current.stop()
    }
    if (recordingTimerRef.current) {
      clearInterval(recordingTimerRef.current)
      recordingTimerRef.current = null
    }
    setIsRecording(false)
    setListening(false)
    setCurrentlyRecordingMessageId(null)
  }

  const handleCancelledRecording = () => {
    // ì·¨ì†Œëœ ë©”ì‹œì§€ ìƒíƒœ ì—…ë°ì´íŠ¸
    if (currentlyRecordingMessageId) {
      setMessages(prev => prev.map(msg => 
        msg.id === currentlyRecordingMessageId 
          ? { ...msg, isCancelled: true, text: "ë…¹ìŒì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤" }
          : msg
      ))
      setCancelledMessageId(currentlyRecordingMessageId)
    }
    
    // ìƒíƒœ ì´ˆê¸°í™”
    setIsRecording(false)
    setListening(false)
    setCurrentlyRecordingMessageId(null)
    setIsProcessing(false)
    
    // 3ì´ˆ í›„ ì·¨ì†Œëœ ë©”ì‹œì§€ ìë™ ì œê±°
    setTimeout(() => {
      setMessages(prev => prev.filter(msg => msg.id !== currentlyRecordingMessageId))
      setCancelledMessageId(null)
    }, 3000)
  }

  const processVadUtterances = async () => {
    setIsProcessing(true)
    
    try {
      const currentUtterances = vadUtterancesRef.current
      if (currentUtterances.length === 0) {
        throw new Error("ë°œí™” êµ¬ê°„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
      }

      // ë°œí™” êµ¬ê°„ë“¤ì„ ì‹œê°„ ìˆœì„œë¡œ ì •ë ¬
      const sortedUtterances = [...currentUtterances].sort((a, b) => a.timestamp - b.timestamp)
      
      // ê° ë°œí™” êµ¬ê°„ì„ STT ì²˜ë¦¬
      const sttPromises = sortedUtterances.map(async (utterance) => {
        try {
          const response = await fetch(utterance.url)
          const blob = await response.blob()
          const sttResponse = await apiClient.stt(blob, { 
            language: "ko",
            prompt: "í•œêµ­ì–´ ëŒ€í™” ì—°ìŠµ" 
          })
          return sttResponse.text.trim()
        } catch (error) {
          console.error('STT error for utterance:', error)
          return ""
        }
      })

      const sttResults = await Promise.all(sttPromises)
      const combinedText = sttResults.filter(text => text.length > 0).join(" ")
      
      if (!combinedText) {
        throw new Error("ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
      }

      // STT ì™„ë£Œ í›„ ì¦‰ì‹œ ì²˜ë¦¬ ìƒíƒœ í•´ì œ
      setIsProcessing(false)

      // Update user message
      console.log('Updating message with VAD result:', combinedText)
      setMessages(prev => {
        let messageUpdated = false
        const updatedMessages = prev.map(msg => {
          if (!messageUpdated && msg.role === "user" && msg.isWaiting) {
            console.log('Found message to update:', msg.id)
            messageUpdated = true
            return { ...msg, text: combinedText, isWaiting: false }
          }
          return msg
        })
        console.log('Updated messages:', updatedMessages)
        return updatedMessages
      })

      // ë‚˜ë¨¸ì§€ ì²˜ë¦¬ëŠ” ê¸°ì¡´ processAudioì™€ ë™ì¼
      await processChatLogic(combinedText)

    } catch (error) {
      console.error("Error processing VAD utterances:", error)
      setIsProcessing(false)
      alert(error instanceof Error ? error.message : "VAD ë°œí™” êµ¬ê°„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    }
  }

  const processChatLogic = async (userText: string) => {
    // Step 2: Prepare shared conversation snapshot
    const memoryHistory = messages
      .filter(msg => !msg.isWaiting && msg.text)
      .map(msg => ({ 
        role: msg.role, 
        text: msg.isFeedback ? `feedback: ${msg.text}` : msg.text 
      }))

    const chatPayload = {
      sessionId,
      userMessage: userText,
      scenarioContext: {
        scenarioId: scenario.id,
        title: scenario.title,
        assistantRole: scenario.role,
        userRole: scenario.userRole,
        description: scenario.description,
        constraints: scenario.constraints || {},
        tasks: scenario.tasks?.map((task: any, idx: number) => ({
          id: `t-${idx}`,
          ko: task.ko,
          en: task.en,
        })) || [],
      },
      progress: {
        currentTaskIndex,
        completed: progress.completed,
        total: progress.total,
      },
      currentTask: currentTask ? {
        id: currentTask.id,
        ko: currentTask.ko,
        en: currentTask.en,
      } : undefined,
      memoryHistory,
    }

    // Step 3: Unified assistant response (includes success check)
      let unifiedResponse: { 
        msg: string | null; 
        success: boolean; 
        show_msg: boolean; 
        feedback: string | null;
      } | undefined
    
    try {
      // Single API call for unified response
      unifiedResponse = await apiClient.chatAssistant(chatPayload).catch((e) => {
        console.error("Assistant error", e)
        return { 
          msg: null, 
          success: false, 
          show_msg: false, 
          feedback: "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”." 
        }
      })

      // Handle unified response
      if (unifiedResponse?.show_msg && unifiedResponse?.msg) {
        // Show assistant message and play TTS
        setAgentSpeaking(true)
        setMessages(prev => {
          const newMessage = { 
            id: `assistant-${Date.now()}`, 
            role: "assistant" as const, 
            text: unifiedResponse?.msg!,
            translateEn: undefined // Will be handled by TTS translation if needed
          }
          return [...prev, newMessage]
        })

        // Assistant ì‘ë‹µ ì‹œ íŒíŠ¸ ìë™ ìˆ¨ê¹€
        setShowHint(false)

        // Stream TTS for the entire text as a single audio stream
        try {
          const audioUrl = await apiClient.getOrCreateTtsObjectUrl(unifiedResponse.msg, {
            sessionId,
            voice: scenario.ttsVoice || "nova",
            format: "mp3",
            instructions: scenario.ttsInstructions,
          })
          const audio = new Audio(audioUrl)
          audioRef.current = audio
          await new Promise<void>((resolve) => {
            audio.onended = () => {
              setAgentSpeaking(false)
              resolve()
            }
            audio.onerror = () => {
              setAgentSpeaking(false)
              resolve()
            }
            audio.play().catch(() => {
              setAgentSpeaking(false)
              resolve()
            })
          })
        } catch (e) {
          console.error("TTS error:", e)
          setAgentSpeaking(false)
        }
      }

      // Latch per-task successes if provided
      if (Array.isArray((unifiedResponse as any)?.task_success)) {
        const arr = (unifiedResponse as any).task_success as boolean[]
        latchTaskSuccesses(arr)
      }

      // Show feedback message if available (regardless of show_msg value)
      if (unifiedResponse?.feedback) {
        const feedback = unifiedResponse.feedback
        setMessages(prev => prev.concat([{ 
          id: `feedback-${Date.now()}`, 
          role: "assistant", 
          text: feedback as string,
          isFeedback: true
        }]))
      }

    } catch (e) {
      console.error("Unified execution error", e)
      setAgentSpeaking(false)
    } finally {
      setMessages(prev => prev.concat([{ id: `user-waiting-${Date.now()}`, role: "user", text: "", isWaiting: true }]))
    }

    // Handle task progress based on unified response
    if (unifiedResponse?.success) {
      markCurrentTaskSuccess()
      setTimeout(() => {
        gotoNextTask()
        saveProgress()
        
        // Success popup is controlled by progress-based effect above
      }, 1500)
    } else {
      // Increment attempts for failed attempts
      incrementAttempts()
    }
  }

  const processAudio = async (audioBlob: Blob) => {
    setIsProcessing(true)
    
    try {
      // Step 1: STT - Convert audio to text
      const sttResponse = await apiClient.stt(audioBlob, { 
        language: "ko",
        prompt: "í•œêµ­ì–´ ëŒ€í™” ì—°ìŠµ" 
      })
      
      const userText = sttResponse.text.trim()
      if (!userText) {
        throw new Error("ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
      }

      // STT ì™„ë£Œ í›„ ì¦‰ì‹œ ì²˜ë¦¬ ìƒíƒœ í•´ì œ
      setIsProcessing(false)

      // Update user message - find and update the waiting user message
      console.log('Updating message:', { currentlyRecordingMessageId, userText })
      setMessages(prev => {
        let messageUpdated = false
        const updatedMessages = prev.map(msg => {
          // Update the first waiting user message (only once)
          if (!messageUpdated && msg.role === "user" && msg.isWaiting) {
            console.log('Found message to update:', msg.id)
            messageUpdated = true
            return { ...msg, text: userText, isWaiting: false }
          }
          return msg
        })
        console.log('Updated messages:', updatedMessages)
        return updatedMessages
      })

      // ë‚˜ë¨¸ì§€ ì²˜ë¦¬ëŠ” ê³µí†µ ë¡œì§ ì‚¬ìš©
      await processChatLogic(userText)

    } catch (error) {
      console.error("Error processing audio:", error)
      setIsProcessing(false) // ì—ëŸ¬ ì‹œì—ë„ ë°˜ë“œì‹œ í•´ì œ
      alert(error instanceof Error ? error.message : "ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    }
  }

  const sendTypedMessage = async (userText: string) => {
    if (!userText.trim()) return
    setIsProcessing(true)
    setTypedMessage("")

    try {
      // Update user message - find and update the waiting user message
      setMessages(prev => {
        let messageUpdated = false
        const updatedMessages = prev.map(msg => {
          if (!messageUpdated && msg.role === "user" && msg.isWaiting) {
            messageUpdated = true
            return { ...msg, text: userText, isWaiting: false }
          }
          return msg
        })
        return updatedMessages
      })

      // Prepare conversation snapshot
      const memoryHistory = messages
        .filter(msg => !msg.isWaiting && msg.text)
        .map(msg => ({ 
          role: msg.role, 
          text: msg.isFeedback ? `feedback: ${msg.text}` : msg.text 
        }))

      const chatPayload = {
        sessionId,
        userMessage: userText,
        scenarioContext: {
          scenarioId: scenario.id,
          title: scenario.title,
          assistantRole: scenario.role,
          userRole: scenario.userRole,
          description: scenario.description,
          constraints: scenario.constraints || {},
          tasks: scenario.tasks?.map((task: any, idx: number) => ({
            id: `t-${idx}`,
            ko: task.ko,
            en: task.en,
          })) || [],
        },
        progress: {
          currentTaskIndex,
          completed: progress.completed,
          total: progress.total,
        },
        currentTask: currentTask ? {
          id: currentTask.id,
          ko: currentTask.ko,
          en: currentTask.en,
        } : undefined,
        memoryHistory,
      }

      // Unified assistant response (includes success check)
      let unifiedResponse: { 
        msg: string | null; 
        success: boolean; 
        show_msg: boolean; 
        feedback: string | null;
      } | undefined
      
      try {
        // Single API call for unified response
        unifiedResponse = await apiClient.chatAssistant(chatPayload).catch((e) => {
          console.error("Assistant error", e)
          return { 
            msg: null, 
            success: false, 
            show_msg: false, 
            feedback: "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”." 
          }
        })

        // Handle unified response
        if (unifiedResponse?.show_msg && unifiedResponse?.msg) {
          setAgentSpeaking(false)
          setMessages(prev => prev.concat([{ 
            id: `assistant-${Date.now()}`, 
            role: "assistant", 
            text: unifiedResponse?.msg!,
            translateEn: undefined
          }]))
          setShowHint(false)
        }

        // Show feedback message if available (regardless of show_msg value)
        if (unifiedResponse?.feedback) {
          const feedback = unifiedResponse.feedback
          setMessages(prev => prev.concat([{ 
            id: `feedback-${Date.now()}`, 
            role: "assistant", 
            text: feedback as string,
            isFeedback: true
          }]))
        }
        

      } catch (e) {
        console.error("Unified execution error", e)
        setAgentSpeaking(false)
      } finally {
        setMessages(prev => prev.concat([{ id: `user-waiting-${Date.now()}`, role: "user", text: "", isWaiting: true }]))
      }

      // Handle task progress based on unified response
      if (unifiedResponse?.success) {
        markCurrentTaskSuccess()
        setTimeout(() => {
          gotoNextTask()
          saveProgress()
          // Success popup is controlled by progress-based effect above
        }, 1500)
      } else {
        incrementAttempts()
      }

    } catch (error) {
      console.error("Error sending typed message:", error)
      alert(error instanceof Error ? error.message : "í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    } finally {
      setIsProcessing(false)
    }
  }

  const handleMicPress = useCallback(() => {
    if (textOnlyMode) return
    if (isAgentSpeaking) {
      // Don't allow recording while agent is speaking
      return
    }
    
    if (isRecording) {
      // ì •ìƒ ì¤‘ë‹¨ (ì·¨ì†Œ ì•„ë‹˜)
      setIsCancelled(false)
      isCancelledRef.current = false
      stopRecording()
    } else if (!isProcessing) {
      startRecording()
    }
  }, [textOnlyMode, isAgentSpeaking, isRecording, isProcessing])


  const handleHint = useCallback(async () => {
    const next = !showHint
    setShowHint(next)
    if (!next) return
    console.log('[Hint] button clicked. showHint ->', next, 'currentTaskIndex:', currentTaskIndex)
    // If we already have a hint for THIS task index, do not refetch
    if (hint && hintTaskIndex === currentTaskIndex) {
      console.log('[Hint] using cached hint for task', hintTaskIndex)
      return
    }
    try {
      setIsHintLoading(true)
      const memoryHistory = messages
        .filter(msg => !msg.isWaiting && msg.text)
        .map(msg => ({ 
          role: msg.role, 
          text: msg.isFeedback ? `feedback: ${msg.text}` : msg.text 
        }))
      const payload = {
        sessionId,
        userMessage: messages.findLast?.((m) => m.role === 'user' && !m.isWaiting && !!m.text)?.text || typedMessage || '',
        scenarioContext: {
          scenarioId: scenario.id,
          title: scenario.title,
          assistantRole: scenario.role,
          userRole: scenario.userRole,
          description: scenario.description,
          constraints: scenario.constraints || {},
          tasks: scenario.tasks?.map((task: any, idx: number) => ({ id: `t-${idx}`, ko: task.ko, en: task.en })) || [],
        },
        progress: {
          currentTaskIndex,
          completed: progress.completed,
          total: progress.total,
        },
        currentTask: currentTask ? {
          id: currentTask.id,
          ko: currentTask.ko,
          en: currentTask.en,
        } : undefined,
        memoryHistory,
      }
      console.log('[Hint] calling chatHint with payload')
      const res = await apiClient.chatHint(payload as any)
      setHint(res.hint)
      setHintTranslateEn(res.hintTranslateEn || null)
      setHintTaskIndex(currentTaskIndex)
      console.log('[Hint] received hint for task', currentTaskIndex)
    } catch (e) {
      console.error("Hint request failed", e)
    } finally {
      setIsHintLoading(false)
    }
  }, [showHint, hint, hintTaskIndex, currentTaskIndex, messages, typedMessage, sessionId, scenario, progress, currentTask])

  const handleSave = () => {
    setIsSaved(!isSaved)
  }

  const playHintTts = async () => {
    if (textOnlyMode) return
    if (!hint || isHintPlaying) return
    
    try {
      setIsHintPlaying(true)
      // Fetch once and cache as Blob object URL
      const audioUrl = await apiClient.getOrCreateTtsObjectUrl(hint, {
        sessionId,
        voice: scenario.ttsVoice || "nova",
        format: "mp3",
        instructions: scenario.ttsInstructions,
      })

      const audio = new Audio(audioUrl)
      hintAudioRef.current = audio
      
      await new Promise<void>((resolve) => {
        audio.onended = () => {
          setIsHintPlaying(false)
          resolve()
        }
        audio.onerror = () => {
          setIsHintPlaying(false)
          resolve()
        }
        audio.play().catch(() => {
          setIsHintPlaying(false)
          resolve()
        })
      })
    } catch (error) {
      console.error("Error playing hint TTS:", error)
      setIsHintPlaying(false)
    }
  }

  const handleSuccessPopupClose = () => {
    setShowSuccessPopup(false)
  }

  const handleSuccessPopupAnalyze = () => {
    // TODO: Implement conversation analysis functionality
    console.log("Analyze conversation")
    setShowSuccessPopup(false)
  }

  const handleMessageTranslationClick = async (messageId: string, text: string) => {
    if (translatingMessageId === messageId) return
    
    try {
      setTranslatingMessageId(messageId)
      const response = await apiClient.translate({ text, targetLanguage: "en" })
      
      // Update the message with translation
      setMessages(prev => prev.map(msg => 
        msg.id === messageId 
          ? { ...msg, translateEn: response.translateEn, translation: response.translateEn }
          : msg
      ))
      // Ensure visibility even if global toggle was off
      setShowAssistantTranslation(true)
    } catch (error) {
      console.error("Translation error:", error)
    } finally {
      setTranslatingMessageId(null)
    }
  }

  const handleHintTranslationClick = async () => {
    if (!hint) return
    
    // ì´ë¯¸ ë²ˆì—­ì´ ìˆê³  í‘œì‹œ ì¤‘ì´ë©´ í† ê¸€
    if (hintTranslateEn && showHintTranslation) {
      setShowHintTranslation(false)
      return
    }
    
    // ë²ˆì—­ì´ ì—†ìœ¼ë©´ API í˜¸ì¶œ
    if (!hintTranslateEn) {
      try {
        setIsHintTranslating(true)
        const response = await apiClient.translate({ 
          text: hint, 
          targetLanguage: "en" 
        })
        setHintTranslateEn(response.translateEn)
        setShowHintTranslation(true)
      } catch (error) {
        console.error("Hint translation error:", error)
      } finally {
        setIsHintTranslating(false)
      }
    } else {
      // ë²ˆì—­ì´ ìˆìœ¼ë©´ í† ê¸€
      setShowHintTranslation(!showHintTranslation)
    }
  }


  const AudioVisualization = useMemo(() => (
    <div className="flex items-center justify-center gap-1 py-4">
      {[...Array(20)].map((_, i) => (
        <div
          key={i}
          className="w-1 bg-primary rounded-full animate-pulse"
          style={{
            height: `${Math.random() * 40 + 10}px`,
            animationDelay: `${i * 0.1}s`,
            animationDuration: "1s",
          }}
        />
      ))}
    </div>
  ), [])

  // Local header components: TaskRail

  const TaskRail = useMemo(() => (
    <div className="flex flex-col md:items-start gap-1 md:gap-2 md:pr-4">
      <div className="flex items-center gap-2 flex-wrap">
        <div className="text-sm md:text-lg font-semibold text-foreground line-clamp-2 break-words">
          {currentTask?.ko || ""}
        </div>
        <span className="text-[11px] md:text-xs text-muted-foreground">
          ({progress.completed}/{progress.total})
        </span>
        <Button
          variant="ghost"
          size="sm"
          className="p-1.5 h-auto"
          onClick={() => setShowAssistantTranslation(!showAssistantTranslation)}
          aria-pressed={showAssistantTranslation}
          title="Toggle translation"
        >
          <Languages className="w-4 h-4" />
        </Button>
      </div>
      {showAssistantTranslation && currentTask?.en && (
        <div className="text-xs md:text-sm text-muted-foreground line-clamp-2 break-words">
          {currentTask.en}
        </div>
      )}
      {progress.total > 0 && (
        <div
          className="flex items-center gap-1.5 md:gap-2 overflow-x-auto no-scrollbar -mx-4 px-4 md:mx-0 md:px-0"
          role="list"
          aria-label={`Task progress: ${progress.completed} of ${progress.total} completed`}
        >
          {Array.from({ length: progress.total }).map((_, index) => {
            const isCompleted = index < progress.completed
            const isCurrent = index === currentTaskIndex
            const base = "rounded-full"
            const size = "w-2.5 h-2.5 md:w-3 md:h-3"
            const color = isCompleted
              ? "bg-primary"
              : isCurrent
              ? "bg-primary/80 ring-2 ring-primary/30"
              : "bg-muted"
            return (
              <motion.div
                key={index}
                className={`${base} ${size} ${color}`}
                initial={{ scale: 0.8, opacity: 0 }}
                animate={{ scale: 1, opacity: 1 }}
                transition={{ duration: 0.2, delay: index * 0.03 }}
                aria-label={`Task ${index + 1} of ${progress.total}${isCurrent ? ", current" : isCompleted ? ", completed" : ""}`}
                role="listitem"
              />
            )
          })}
        </div>
      )}
    </div>
  ), [currentTask, progress, showAssistantTranslation, currentTaskIndex])

  return (
    <div className="min-h-screen bg-background flex flex-col">
      {/* Sticky Header (Header + Task Rail) */}
      <div className="sticky top-0 z-50 bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60 border-b border-border">
        {/* Header */}
        <div className="flex items-center justify-between p-4 border-b border-border">
          <Button variant="ghost" size="sm" onClick={onBack} className="p-2">
            <X className="w-5 h-5" />
          </Button>
          <h1 className="text-lg font-bold text-balance">{scenario.title}</h1>
          <div className="flex items-center gap-2">
            <Button
              variant={textOnlyMode ? "default" : "ghost"}
              size="sm"
              className="p-2"
              onClick={() => setTextOnlyMode((v) => !v)}
              title="Toggle Text-only Chat Mode"
            >
              Text Mode
            </Button>
            <Button variant="ghost" size="sm" className="p-2">
              <Settings className="w-5 h-5" />
            </Button>
          </div>
        </div>

        {/* Task Rail Header */}
        <AnimatePresence mode="wait">
          <motion.div
            key={`task-rail-${currentTaskIndex}-${progress.completed}-${progress.total}`}
            className="px-4 py-3 bg-muted/20"
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            exit={{ opacity: 0, y: -10 }}
            transition={{ duration: 0.25 }}
          >
            <div className="flex flex-col md:flex-row items-start md:items-center justify-between gap-3">
              {TaskRail}
            </div>
          </motion.div>
        </AnimatePresence>
      </div>

      {/* Messages Container */}
      <div className="flex-1 px-4 py-6 overflow-y-auto">
        <div className="max-w-2xl mx-auto space-y-4">
          <AnimatePresence>
            {messages.map((message) => {
              // í”¼ë“œë°± ë©”ì‹œì§€ëŠ” ê°€ìš´ë° ì •ë ¬ë¡œ ë³„ë„ ë Œë”ë§
              if (message.isFeedback) {
                return (
                  <motion.div
                    key={message.id}
                    className="flex justify-center"
                    initial={{ opacity: 0, y: 20 }}
                    animate={{ opacity: 1, y: 0 }}
                    exit={{ opacity: 0, y: -20 }}
                    transition={{ duration: 0.3 }}
                  >
                    <div className="max-w-[80%] md:max-w-[70%]">
                      <Card className="bg-amber-50 border-amber-200 border-2">
                        <CardContent className="p-3">
                          <div className="flex items-center gap-2 mb-1">
                            <div className="w-2 h-2 bg-amber-500 rounded-full"></div>
                            <span className="text-xs font-medium text-amber-700">Feedback</span>
                          </div>
                          <p className="text-sm font-medium text-amber-900">{message.text}</p>
                        </CardContent>
                      </Card>
                    </div>
                  </motion.div>
                )
              }
              
              // ì¼ë°˜ ë©”ì‹œì§€ ë Œë”ë§
              return (
                <motion.div
                key={message.id}
                className={`flex ${message.role === "user" ? "justify-end" : "justify-start"}`}
                initial={{ opacity: 0, y: 20 }}
                animate={{ opacity: 1, y: 0 }}
                exit={{ opacity: 0, y: -20 }}
                transition={{ duration: 0.3 }}
              >
                <div className={`max-w-[80%] md:max-w-[70%] ${message.role === "user" ? "order-2" : "order-1"}`}>
                  <Card className={`${
                    message.role === "user" 
                      ? "bg-primary text-primary-foreground" 
                      : "bg-card"
                  }`}>
                    <CardContent className="p-4">
                      {message.role === "assistant" ? (
                        <>
                          <p className="font-medium mb-3">{message.text}</p>
                          {(showAssistantTranslation || !!message.translateEn) && (message.translation || message.translateEn) && (
                            <motion.p
                              className="text-sm opacity-70 mb-3"
                              initial={{ opacity: 0, height: 0 }}
                              animate={{ opacity: 1, height: "auto" }}
                              exit={{ opacity: 0, height: 0 }}
                            >
                              {message.translateEn || message.translation}
                            </motion.p>
                          )}
                          <div className="flex items-center gap-2">
                            <Button 
                              variant="ghost" 
                              size="sm" 
                              className="p-1.5 h-auto"
                              onClick={async () => {
                                if (textOnlyMode) return
                                try {
                                  const audioUrl = await apiClient.getOrCreateTtsObjectUrl(message.text, {
                                    sessionId,
                                    voice: scenario.ttsVoice || "nova",
                                    format: "mp3",
                                    instructions: scenario.ttsInstructions,
                                  })
                                  const audio = new Audio(audioUrl)
                                  audio.play().catch(() => {})
                                } catch {}
                              }}
                            >
                              <Volume2 className="w-4 h-4" />
                            </Button>
                            <Button 
                              variant="ghost" 
                              size="sm" 
                              className="p-1.5 h-auto" 
                              onClick={() => handleMessageTranslationClick(message.id, message.text)}
                              disabled={translatingMessageId === message.id}
                            >
                              {translatingMessageId === message.id ? (
                                <Loader2 className="w-4 h-4 animate-spin" />
                              ) : (
                                <Languages className="w-4 h-4" />
                              )}
                            </Button>
                            <Button variant="ghost" size="sm" className="p-1.5 h-auto">
                              <Eye className="w-4 h-4" />
                            </Button>
                            <Button
                              variant="ghost"
                              size="sm"
                              className={`p-1.5 h-auto ml-auto ${isSaved ? "text-primary" : ""}`}
                              onClick={handleSave}
                            >
                              <Bookmark className={`w-4 h-4 ${isSaved ? "fill-current" : ""}`} />
                            </Button>
                          </div>
                        </>
                      ) : (
                        <div className="text-center">
                          {message.isWaiting && !isRecording && !isProcessing && (
                            <div className="flex items-center justify-center">
                              <span className="text-sm opacity-70">Press Record</span>
                            </div>
                          )}
                          {isRecording && currentlyRecordingMessageId === message.id && (
                            <>
                              <span className="text-sm opacity-70 mb-2 block">
                                Recording... {Math.floor(recordingDuration / 60)}:{(recordingDuration % 60).toString().padStart(2, '0')}
                              </span>
                              {AudioVisualization}
                            </>
                          )}
                          {isProcessing && (
                            <div className="flex items-center justify-center gap-2">
                              <Loader2 className="w-4 h-4 animate-spin" />
                              <span className="text-sm opacity-70">Processing...</span>
                            </div>
                          )}
                          {message.text && !message.isWaiting && !message.isCancelled && (
                            <p className="font-medium">{message.text}</p>
                          )}
                          {message.text && message.isWaiting && isProcessing && (
                            <p className="font-medium opacity-70">{message.text}</p>
                          )}
                          {message.isCancelled && (
                            <motion.p 
                              className="font-medium text-muted-foreground italic"
                              initial={{ opacity: 0, scale: 0.8 }}
                              animate={{ opacity: 1, scale: 1 }}
                              exit={{ opacity: 0, scale: 0.8 }}
                              transition={{ duration: 0.3 }}
                            >
                              {message.text}
                            </motion.p>
                          )}
                        </div>
                      )}
                    </CardContent>
                  </Card>
                </div>
                </motion.div>
              )
            })}
          </AnimatePresence>
        </div>
      </div>

      {/* VAD Error Display - ë‹¨ìˆœí™” */}
      <AnimatePresence>
        {vadErrorMessage && (
          <motion.div
            className="px-4 pb-2"
            initial={{ opacity: 0, y: -20 }}
            animate={{ opacity: 1, y: 0 }}
            exit={{ opacity: 0, y: -20 }}
          >
            <div className="max-w-2xl mx-auto">
              <div className="bg-yellow-50 border border-yellow-200 rounded-lg p-3">
                <div className="flex items-start gap-2">
                  <div className="w-5 h-5 rounded-full bg-yellow-500 flex items-center justify-center flex-shrink-0 mt-0.5">
                    <div className="w-2 h-2 rounded-full bg-white"></div>
                  </div>
                  <div className="flex-1">
                    <p className="text-sm font-medium text-yellow-900">ìŒì„± ì¸ì‹ ê²½ê³ </p>
                    <p className="text-sm text-yellow-700 mt-1">
                      ê³ ê¸‰ ìŒì„± ì¸ì‹ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì „ì²´ ì˜¤ë””ì˜¤ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
                    </p>
                  </div>
                </div>
              </div>
            </div>
          </motion.div>
        )}
      </AnimatePresence>

      {/* Feedback Display */}
      <AnimatePresence>
        {feedback && (
          <motion.div
            className="px-4 pb-2"
            initial={{ opacity: 0, y: -20 }}
            animate={{ opacity: 1, y: 0 }}
            exit={{ opacity: 0, y: -20 }}
          >
            <div className="max-w-2xl mx-auto">
              <div className="bg-blue-50 border border-blue-200 rounded-lg p-3">
                <div className="flex items-start gap-2">
                  <div className="w-5 h-5 rounded-full bg-blue-500 flex items-center justify-center flex-shrink-0 mt-0.5">
                    <div className="w-2 h-2 rounded-full bg-white"></div>
                  </div>
                  <div className="flex-1">
                    <p className="text-sm font-medium text-blue-900">Feedback</p>
                    <p className="text-sm text-blue-700 mt-1">{feedback}</p>
                  </div>
                </div>
              </div>
            </div>
          </motion.div>
        )}
      </AnimatePresence>

      {/* Score Display removed per new design */}

      {showHint && (
        <motion.div
          className="px-4 pb-4"
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          exit={{ opacity: 0, y: -20 }}
          transition={{ duration: 0.3 }}
        >
          <div className="max-w-2xl mx-auto">
            <Card className="border-2 border-dashed border-primary/30 bg-primary/5">
              <CardContent className="p-4">
                <div className="flex items-start gap-3">
                  <div className="text-sm">
                    <span className="font-medium text-primary">TRY SAYING:</span>
                    <p className="mt-1">{hint || "íŒíŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."}</p>
                    {showHintTranslation && hintTranslateEn && (
                      <motion.p
                        className="text-sm opacity-70 mt-2"
                        initial={{ opacity: 0, height: 0 }}
                        animate={{ opacity: 1, height: "auto" }}
                        exit={{ opacity: 0, height: 0 }}
                      >
                        {hintTranslateEn}
                      </motion.p>
                    )}
                  </div>
                  <div className="flex gap-2 ml-auto">
                    {hint && !textOnlyMode && (
                      <Button 
                        variant="ghost" 
                        size="sm" 
                        className="p-1.5 h-auto"
                        onClick={playHintTts}
                        disabled={isHintPlaying}
                      >
                        {isHintPlaying ? (
                          <Loader2 className="w-4 h-4 animate-spin" />
                        ) : (
                          <Volume2 className="w-4 h-4" />
                        )}
                      </Button>
                    )}
                    <Button 
                      variant="ghost" 
                      size="sm" 
                      className="p-1.5 h-auto"
                      onClick={handleHintTranslationClick}
                      disabled={isHintTranslating}
                    >
                      {isHintTranslating ? (
                        <Loader2 className="w-4 h-4 animate-spin" />
                      ) : (
                        <Languages className="w-4 h-4" />
                      )}
                    </Button>
                    {isHintLoading && (
                      <Loader2 className="w-4 h-4 animate-spin" />
                    )}
                  </div>
                </div>
              </CardContent>
            </Card>
          </div>
        </motion.div>
      )}


      {/* Bottom Controls */}
      <div className="p-4 bg-background border-t border-border">
        <div className="max-w-2xl mx-auto">
          {!textOnlyMode ? (
          <div className="flex items-center justify-center gap-4">
            {isRecording && (
              <motion.div
                initial={{ scale: 0 }}
                animate={{ scale: 1 }}
                exit={{ scale: 0 }}
              >
                <Button
                  variant="outline"
                  size="lg"
                  className="w-16 h-16 rounded-full bg-destructive/10 border-destructive/30 hover:bg-destructive/20"
                  onClick={() => {
                    console.log('Cancel button clicked')
                    setIsCancelled(true)
                    isCancelledRef.current = true
                    stopRecording()
                  }}
                  title="ë…¹ìŒ ì·¨ì†Œ"
                >
                  <X className="w-6 h-6 text-destructive" />
                </Button>
              </motion.div>
            )}

            <motion.div
              animate={{
                scale: isRecording ? [1, 1.1, 1] : 1,
              }}
              transition={{
                duration: 1,
                repeat: isRecording ? Infinity : 0,
              }}
            >
              <Button
                size="lg"
                className={`w-20 h-20 rounded-full transition-all duration-300 ${
                  isRecording
                    ? "bg-red-500 hover:bg-red-600 shadow-lg shadow-red-500/25"
                    : isProcessing
                    ? "bg-yellow-500 hover:bg-yellow-600"
                    : isAgentSpeaking
                    ? "bg-blue-500 hover:bg-blue-600 shadow-lg shadow-blue-500/25"
                    : "bg-primary hover:bg-primary/90"
                }`}
                onClick={handleMicPress}
                disabled={isProcessing || isAgentSpeaking}
              >
                {isProcessing ? (
                  <Loader2 className="w-8 h-8 animate-spin" />
                ) : isAgentSpeaking ? (
                  <Volume2 className="w-8 h-8" />
                ) : isRecording ? (
                  <ArrowUp className="w-8 h-8" />
                ) : (
                  <Mic className="w-8 h-8" />
                )}
              </Button>
            </motion.div>

            {/* íŒíŠ¸ ë²„íŠ¼ - ìƒˆë¡œ ì¶”ê°€ */}
            <motion.div
              initial={{ scale: 0 }}
              animate={{ scale: 1 }}
              exit={{ scale: 0 }}
              transition={{ duration: 0.2 }}
            >
              <Button
                variant="outline"
                size="lg"
                className={`w-16 h-16 rounded-full transition-all duration-300 ${
                  showHint 
                    ? "bg-primary/10 border-primary/30 hover:bg-primary/20" 
                    : "hover:bg-muted/50"
                }`}
                onClick={handleHint}
                disabled={isAgentSpeaking}
              >
                <Lightbulb className={`w-6 h-6 ${showHint ? "text-primary" : ""}`} />
              </Button>
            </motion.div>
          </div>
          ) : (
          <div className="flex items-center gap-2">
            <Input
              placeholder="Type your message in Korean..."
              value={typedMessage}
              onChange={(e) => setTypedMessage(e.target.value)}
              onKeyDown={(e) => {
                if (e.key === 'Enter') {
                  const text = typedMessage.trim()
                  if (!text || isProcessing || isAgentSpeaking) return
                  ;(async () => {
                    await sendTypedMessage(text)
                  })()
                }
              }}
            />
            <Button
              onClick={async () => {
                const text = typedMessage.trim()
                if (!text || isProcessing || isAgentSpeaking) return
                await sendTypedMessage(text)
              }}
              disabled={!typedMessage.trim() || isProcessing || isAgentSpeaking}
            >
              Send
            </Button>
            <Button
              variant="outline"
              onClick={handleHint}
              disabled={isAgentSpeaking}
            >
              <Lightbulb className="w-4 h-4" />
            </Button>
          </div>
          )}
        </div>
      </div>

      {/* Success Popup */}
      <SuccessPopup
        isOpen={showSuccessPopup}
        onClose={handleSuccessPopupClose}
        onAnalyze={handleSuccessPopupAnalyze}
      />
    </div>
  )
}
