// TTS API í´ë¼ì´ì–¸íŠ¸ ì„œë¹„ìŠ¤

export type TtsOptions = {
  sessionId: string
  text: string
  voice?: string
  format?: 'mp3' | 'wav'
  sampleRate?: number
}

export class TtsService {
  private baseUrl: string

  constructor(baseUrl: string = 'http://localhost:3001') {
    this.baseUrl = baseUrl
  }

  /**
   * í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
   */
  async synthesizeSpeech(options: TtsOptions): Promise<Blob> {
    const {
      sessionId,
      text,
      voice = 'alloy',
      format = 'mp3',
      sampleRate = 24000
    } = options

    console.log('ğŸ”Š Synthesizing speech:', { text: text.substring(0, 50) + '...', voice, format })

    const params = new URLSearchParams({
      sessionId,
      text,
      voice,
      format,
      sampleRate: sampleRate.toString()
    })

    const response = await fetch(`${this.baseUrl}/api/openai/text-to-speech?${params}`, {
      method: 'GET',
      credentials: 'include',
      signal: AbortSignal.timeout(30000) // 30ì´ˆ íƒ€ì„ì•„ì›ƒ
    })

    if (!response.ok) {
      let errorMessage = 'ìŒì„± í•©ì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
      
      try {
        const errorData = await response.json()
        errorMessage = errorData.error || errorMessage
      } catch {
        // JSONì´ ì•„ë‹Œ ê²½ìš° í…ìŠ¤íŠ¸ë¡œ ì‹œë„
        try {
          const errorText = await response.text()
          if (errorText) errorMessage = errorText
        } catch {
          // ë‘˜ ë‹¤ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš©
        }
      }
      
      if (response.status >= 500) {
        errorMessage = `ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (${response.status})`
      } else if (response.status === 429) {
        errorMessage = 'ë„ˆë¬´ ë§ì€ ìš”ì²­ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      } else if (response.status === 401) {
        errorMessage = 'API ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.'
      } else if (response.status === 400) {
        errorMessage = 'ì˜ëª»ëœ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ë‚´ìš©ìœ¼ë¡œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      } else if (response.status === 413) {
        errorMessage = 'í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ë” ì§§ê²Œ ì¤„ì—¬ì£¼ì„¸ìš”.'
      }
      
      throw new Error(errorMessage)
    }

    const audioBlob = await response.blob()
    
    if (audioBlob.size === 0) {
      throw new Error('ìŒì„± íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')
    }
    
    console.log('âœ… TTS synthesis complete:', audioBlob.size, 'bytes')
    
    return audioBlob
  }

  /**
   * ì˜¤ë””ì˜¤ ì¬ìƒ
   */
  async playAudio(audioBlob: Blob): Promise<HTMLAudioElement> {
    return new Promise((resolve, reject) => {
      try {
        const audioUrl = URL.createObjectURL(audioBlob)
        const audio = new Audio(audioUrl)
        
        audio.onloadeddata = () => {
          console.log('ğŸµ Audio loaded, duration:', audio.duration, 'seconds')
        }
        
        audio.onended = () => {
          console.log('ğŸµ Audio playback finished')
          URL.revokeObjectURL(audioUrl)
          resolve(audio)
        }
        
        audio.onerror = (error) => {
          console.error('âŒ Audio playback error:', error)
          URL.revokeObjectURL(audioUrl)
          reject(new Error('Audio playback failed'))
        }
        
        audio.play().catch(reject)
        console.log('ğŸ”Š Starting audio playback...')
        
      } catch (error) {
        console.error('âŒ Audio setup error:', error)
        reject(error)
      }
    })
  }

  /**
   * í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¬ìƒ
   */
  async speakText(options: TtsOptions): Promise<HTMLAudioElement> {
    try {
      console.log('ğŸ—£ï¸ Speaking text:', options.text.substring(0, 100) + '...')
      
      // 1. TTS API í˜¸ì¶œ
      const audioBlob = await this.synthesizeSpeech(options)
      
      // 2. ì˜¤ë””ì˜¤ ì¬ìƒ
      const audio = await this.playAudio(audioBlob)
      
      return audio
      
    } catch (error) {
      console.error('âŒ Text-to-speech failed:', error)
      throw error
    }
  }
}

// Mock TTS ì„œë¹„ìŠ¤ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
export class MockTtsService extends TtsService {
  async synthesizeSpeech(options: TtsOptions): Promise<Blob> {
    console.log('ğŸ§ª Mock TTS - Synthesizing:', options.text.substring(0, 50) + '...')
    
    // ëª¨ì˜ ì§€ì—°
    await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 2000))
    
    // ê°„ë‹¨í•œ ì‚¬ì¸íŒŒ ì˜¤ë””ì˜¤ ìƒì„± (440Hz, 2ì´ˆ)
    const sampleRate = options.sampleRate || 24000
    const duration = 2 // 2ì´ˆ
    const frequency = 440 // 440Hz (A4 ìŒ)
    const samples = sampleRate * duration
    
    // 16-bit PCM WAV ìƒì„±
    const buffer = new ArrayBuffer(44 + samples * 2)
    const view = new DataView(buffer)
    
    // WAV í—¤ë”
    const writeString = (offset: number, str: string) => {
      for (let i = 0; i < str.length; i++) {
        view.setUint8(offset + i, str.charCodeAt(i))
      }
    }
    
    writeString(0, 'RIFF')
    view.setUint32(4, 36 + samples * 2, true)
    writeString(8, 'WAVE')
    writeString(12, 'fmt ')
    view.setUint32(16, 16, true)
    view.setUint16(20, 1, true) // PCM
    view.setUint16(22, 1, true) // mono
    view.setUint32(24, sampleRate, true)
    view.setUint32(28, sampleRate * 2, true)
    view.setUint16(32, 2, true)
    view.setUint16(34, 16, true)
    writeString(36, 'data')
    view.setUint32(40, samples * 2, true)
    
    // ì‚¬ì¸íŒŒ ì˜¤ë””ì˜¤ ë°ì´í„°
    for (let i = 0; i < samples; i++) {
      const sample = Math.sin(2 * Math.PI * frequency * i / sampleRate) * 0.1
      view.setInt16(44 + i * 2, sample * 32767, true)
    }
    
    const audioBlob = new Blob([buffer], { type: 'audio/wav' })
    console.log('ğŸ§ª Mock TTS complete:', audioBlob.size, 'bytes')
    
    return audioBlob
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
export const ttsService = new TtsService()

// ê°œë°œ ëª¨ë“œì—ì„œëŠ” Mock ì„œë¹„ìŠ¤ ì‚¬ìš©
export const isDevelopment = process.env.NODE_ENV === 'development'
export const activeTtsService = isDevelopment ? new MockTtsService() : ttsService
